{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:20:21.578886Z",
     "iopub.status.busy": "2025-04-12T02:20:21.578353Z",
     "iopub.status.idle": "2025-04-12T02:21:56.014704Z",
     "shell.execute_reply": "2025-04-12T02:21:56.013874Z",
     "shell.execute_reply.started": "2025-04-12T02:20:21.578861Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install tqdm\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:38:56.348468Z",
     "iopub.status.busy": "2025-04-12T02:38:56.348047Z",
     "iopub.status.idle": "2025-04-12T02:38:56.354387Z",
     "shell.execute_reply": "2025-04-12T02:38:56.353721Z",
     "shell.execute_reply.started": "2025-04-12T02:38:56.348447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18, ResNet18_Weights, vgg11 , VGG11_Weights, resnet50, ResNet50_Weights,  mobilenet_v2, MobileNet_V2_Weights\n",
    "from torchvision.transforms import (Compose,\n",
    "                                    RandomResizedCrop,\n",
    "                                    RandomHorizontalFlip,\n",
    "                                    ToTensor,\n",
    "                                    Normalize,\n",
    "                                    Resize,\n",
    "                                    CenterCrop\n",
    "                                    )\n",
    "import argparse\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các hyper parameter mặc định cho việc train. Trong đó có một vài cái là đường dẫn file kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:38:56.364205Z",
     "iopub.status.busy": "2025-04-12T02:38:56.363620Z",
     "iopub.status.idle": "2025-04-12T02:38:56.377872Z",
     "shell.execute_reply": "2025-04-12T02:38:56.377230Z",
     "shell.execute_reply.started": "2025-04-12T02:38:56.364188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_arg():\n",
    "    parse = argparse.ArgumentParser(description='Transfer learning')\n",
    "    parse.add_argument('--epochs', '-e', type=int, default=100, help='Số lượng epoch để chạy')\n",
    "    parse.add_argument('--checkpoint-dir', '-d', type=str, default='/kaggle/working/checkpoint', help='Nơi lưu checkpoint - weght của model')\n",
    "    parse.add_argument('--tensorboard', '-t', type=str, default='/kaggle/working/dashboad', help='Nơi lưu file .event trực quan hóa')\n",
    "    parse.add_argument('--lr', '-l', type=float, default=1e-3)\n",
    "    parse.add_argument('--EarlyStopping','-s',type=int, default=70, help='Early stopping càng lớn thì train được càng nhiều')\n",
    "    parse.add_argument('--batch-size','-b',type=int, default=16, help='Kích thước mỗi batch cho vào mô hình')\n",
    "    args, unknown = parse.parse_known_args()\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiền xử lý dữ liệu bằng data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:38:56.379399Z",
     "iopub.status.busy": "2025-04-12T02:38:56.379067Z",
     "iopub.status.idle": "2025-04-12T02:38:56.398774Z",
     "shell.execute_reply": "2025-04-12T02:38:56.398163Z",
     "shell.execute_reply.started": "2025-04-12T02:38:56.379384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Đường dẫn tới dataset trên kaggle (tùy chỉnh trước khi chạy)\n",
    "temp_val = '/kaggle/input/aio-hutech/test'\n",
    "temp_train = '/kaggle/input/aio-hutech/train'\n",
    "test_path = \"/kaggle/input/aio-hutech/submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:38:56.400350Z",
     "iopub.status.busy": "2025-04-12T02:38:56.399648Z",
     "iopub.status.idle": "2025-04-12T02:38:56.415994Z",
     "shell.execute_reply": "2025-04-12T02:38:56.415329Z",
     "shell.execute_reply.started": "2025-04-12T02:38:56.400329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(dataset_path):\n",
    "    transforms = Compose([\n",
    "            RandomResizedCrop(224),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            Normalize([0.574, 0.574, 0.574], [0.169, 0.169, 0.169])\n",
    "        ])\n",
    "\n",
    "    dataset = ImageFolder(root=dataset_path, transform=transforms)\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá mô hình bằng metrics accuracy khi cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:38:56.417343Z",
     "iopub.status.busy": "2025-04-12T02:38:56.417074Z",
     "iopub.status.idle": "2025-04-12T02:38:56.431324Z",
     "shell.execute_reply": "2025-04-12T02:38:56.430672Z",
     "shell.execute_reply.started": "2025-04-12T02:38:56.417324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def metrics_evaluations(writer, optimizer, epoch, score, metrics, name, model,\n",
    "                        model_checkpoint_path):\n",
    "    writer.add_scalar(tag=f'{name}/val', scalar_value=score, global_step=epoch)\n",
    "\n",
    "    # show kết quả\n",
    "\n",
    "    checkpoint = {\n",
    "        'state': model.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'best_epoch': metrics['best_epoch'],\n",
    "        f'best_{name}': metrics[f'best_{name}']\n",
    "    }    \n",
    "    \n",
    "    if metrics[f'best_{name}'] < score:\n",
    "        metrics[f'best_{name}'] = score\n",
    "        metrics[f'best_epoch'] = epoch\n",
    "        torch.save(checkpoint, model_checkpoint_path + '/' + f'best_{name}.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tái huấn luyện mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:38:56.432513Z",
     "iopub.status.busy": "2025-04-12T02:38:56.432227Z",
     "iopub.status.idle": "2025-04-12T02:38:56.455807Z",
     "shell.execute_reply": "2025-04-12T02:38:56.455316Z",
     "shell.execute_reply.started": "2025-04-12T02:38:56.432487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def transfer_learning(model, model_name, classes, criterion, optimizer, parse, data_loader):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    metrics = {\n",
    "                'best_accuracy' : -999,\n",
    "                'best_epoch' : 0\n",
    "    }\n",
    "    # Create a SummaryWriter for TensorBoard\n",
    "    writer = SummaryWriter(parse.tensorboard)\n",
    "    \n",
    "    for epoch in range(parse.epochs):\n",
    "        print('-' * 10)\n",
    "        print(f'Epoch {epoch + 1}/{parse.epochs}')\n",
    "\n",
    "        # training\n",
    "        model.train()\n",
    "        loss_recorded = []\n",
    "        all_pred = []\n",
    "        all_labels = []\n",
    "\n",
    "        progress_bar = tqdm(data_loader, colour='yellow')\n",
    "        for iter, (images, labels) in enumerate(progress_bar):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # foward\n",
    "            pred = model(images)\n",
    "            max_pred = torch.argmax(pred, dim=1)\n",
    "            loss = criterion(pred, labels)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            # ghi nhận loss\n",
    "            all_labels.extend(labels.tolist())\n",
    "            all_pred.extend(max_pred.tolist())\n",
    "            loss_recorded.append(loss.item())\n",
    "\n",
    "            progress_bar.set_description(f'Train/Batch {iter}, Loss: {loss.item():.4f}')\n",
    "            writer.add_scalar(tag='Train/Loss', scalar_value=np.mean(loss_recorded),\n",
    "                              global_step=epoch * len(data_loader) + iter)\n",
    "\n",
    "        # numerical metrics\n",
    "        acc = accuracy_score(all_labels, all_pred)\n",
    "        writer.add_scalar(tag='Train/Accuracy', scalar_value=acc,\n",
    "                          global_step=epoch * len(data_loader) + iter)\n",
    "        print(f'Acc: {acc:.4f}, avg_oss: {np.mean(loss_recorded):.4f}')\n",
    "        if abs(metrics['best_epoch'] - epoch) >= parse.EarlyStopping:\n",
    "            break\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:38:56.497837Z",
     "iopub.status.busy": "2025-04-12T02:38:56.497668Z",
     "iopub.status.idle": "2025-04-12T02:38:58.084680Z",
     "shell.execute_reply": "2025-04-12T02:38:58.083871Z",
     "shell.execute_reply.started": "2025-04-12T02:38:56.497825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = preprocessing(dataset_path=temp_train)\n",
    "parse = parse_arg()\n",
    "classes = ['nấm mỡ', 'bào ngư xám + trắng', 'Đùi gà Baby (cắt ngắn)', 'linh chi trắng']\n",
    "\n",
    "# criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Một vài chiến lược cải thiện mô hình bằng hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Early stopping\n",
    "  + Càng nhỏ thì học càng nhanh, nhưng độ chính xác không cao\n",
    "  + Càng lớn thì độ chính xác cao nhưng mô hình học càng chậm,\n",
    "\n",
    "- learning rate\n",
    "  + Càng nhỏ thì càng tối ưu nhưng chạy chậm\n",
    "  + Càng lớn thì ngược lại\n",
    "\n",
    "- Batch size\n",
    "  + Càng nhỏ: Tiêu tốn ít RAM hơn, tổng quát hóa tốt hơn, nhưng chậm\n",
    "  + Càng lớn: Tiêu tốn nhiều RAM hơn, dễ bị overfit\n",
    "  \n",
    "- optimizer\n",
    "  + Adam\n",
    "  + SGD\n",
    "  + Adagrad\n",
    "  + momemtum\n",
    "    \n",
    "- Đổi mô hình:\n",
    "    + Mô hình càng lớn, dữ liệu càng nhỏ thì dễ bị overfiting\n",
    "\n",
    "      Giải pháp: chọn mô hình nhỏ hơn để phù hợp với dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chạy thử với mô hình mobilenet_v3_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:38:58.086593Z",
     "iopub.status.busy": "2025-04-12T02:38:58.085879Z",
     "iopub.status.idle": "2025-04-12T02:42:34.956146Z",
     "shell.execute_reply": "2025-04-12T02:42:34.955367Z",
     "shell.execute_reply.started": "2025-04-12T02:38:58.086574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.6635: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.6100, avg_oss: 1.0651\n",
      "----------\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.7705: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 23.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8183, avg_oss: 0.5781\n",
      "----------\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.3188: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8467, avg_oss: 0.4367\n",
      "----------\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.5861: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8842, avg_oss: 0.3284\n",
      "----------\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2199: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8992, avg_oss: 0.2963\n",
      "----------\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2212: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8883, avg_oss: 0.3178\n",
      "----------\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.4375: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9125, avg_oss: 0.2531\n",
      "----------\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1482: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9133, avg_oss: 0.2521\n",
      "----------\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0474: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9183, avg_oss: 0.2320\n",
      "----------\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.4536: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9275, avg_oss: 0.2225\n",
      "----------\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1674: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9142, avg_oss: 0.2253\n",
      "----------\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1707: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9250, avg_oss: 0.2170\n",
      "----------\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0313: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9217, avg_oss: 0.2209\n",
      "----------\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1096: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9375, avg_oss: 0.1911\n",
      "----------\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.5537: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9308, avg_oss: 0.2108\n",
      "----------\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1452: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9292, avg_oss: 0.2155\n",
      "----------\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2290: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9292, avg_oss: 0.1888\n",
      "----------\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2552: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9400, avg_oss: 0.1653\n",
      "----------\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0734: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9367, avg_oss: 0.1642\n",
      "----------\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0407: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9325, avg_oss: 0.1842\n",
      "----------\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.4056: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9433, avg_oss: 0.1629\n",
      "----------\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.5535: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9425, avg_oss: 0.1576\n",
      "----------\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2571: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 23.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9558, avg_oss: 0.1313\n",
      "----------\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.3331: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9500, avg_oss: 0.1405\n",
      "----------\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2453: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9408, avg_oss: 0.1383\n",
      "----------\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1242: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9542, avg_oss: 0.1526\n",
      "----------\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0295: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9500, avg_oss: 0.1448\n",
      "----------\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0204: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9567, avg_oss: 0.1312\n",
      "----------\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.3858: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9508, avg_oss: 0.1288\n",
      "----------\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1463: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9558, avg_oss: 0.1286\n",
      "----------\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.3554: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9417, avg_oss: 0.1587\n",
      "----------\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2448: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9558, avg_oss: 0.1349\n",
      "----------\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.3866: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9625, avg_oss: 0.1022\n",
      "----------\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0084: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9650, avg_oss: 0.1058\n",
      "----------\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0157: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9525, avg_oss: 0.1450\n",
      "----------\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0566: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9608, avg_oss: 0.1224\n",
      "----------\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0809: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9558, avg_oss: 0.1227\n",
      "----------\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1355: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9658, avg_oss: 0.1018\n",
      "----------\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0393: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9658, avg_oss: 0.1083\n",
      "----------\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1553: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9642, avg_oss: 0.1093\n",
      "----------\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0176: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9567, avg_oss: 0.1289\n",
      "----------\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0427: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9658, avg_oss: 0.0990\n",
      "----------\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2574: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9533, avg_oss: 0.1216\n",
      "----------\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1013: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 23.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9667, avg_oss: 0.1001\n",
      "----------\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.2212: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9675, avg_oss: 0.0860\n",
      "----------\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0158: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9600, avg_oss: 0.1181\n",
      "----------\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0440: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9558, avg_oss: 0.1293\n",
      "----------\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0297: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9683, avg_oss: 0.0900\n",
      "----------\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1298: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9625, avg_oss: 0.0997\n",
      "----------\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1763: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9508, avg_oss: 0.1417\n",
      "----------\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0374: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9550, avg_oss: 0.1279\n",
      "----------\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1003: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9625, avg_oss: 0.0978\n",
      "----------\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1495: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9567, avg_oss: 0.1098\n",
      "----------\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.3230: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 23.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9600, avg_oss: 0.1071\n",
      "----------\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1050: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9575, avg_oss: 0.1159\n",
      "----------\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0060: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9567, avg_oss: 0.0991\n",
      "----------\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0122: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9633, avg_oss: 0.1002\n",
      "----------\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0517: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9633, avg_oss: 0.0983\n",
      "----------\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1638: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9658, avg_oss: 0.0932\n",
      "----------\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0174: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9617, avg_oss: 0.1008\n",
      "----------\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1599: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9675, avg_oss: 0.0889\n",
      "----------\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0573: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9725, avg_oss: 0.0827\n",
      "----------\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0038: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9658, avg_oss: 0.1032\n",
      "----------\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0691: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9567, avg_oss: 0.1138\n",
      "----------\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0218: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 23.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9758, avg_oss: 0.0887\n",
      "----------\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1016: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9733, avg_oss: 0.0814\n",
      "----------\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0466: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9742, avg_oss: 0.0773\n",
      "----------\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0604: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:02<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9733, avg_oss: 0.0746\n",
      "----------\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.1060: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9717, avg_oss: 0.0834\n",
      "----------\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0337: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9667, avg_oss: 0.0894\n",
      "----------\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train/Batch 74, Loss: 0.0087: 100%|\u001b[33m██████████\u001b[0m| 75/75 [00:03<00:00, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9708, avg_oss: 0.0912\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------- mobilenet_v3_small ---------------------------------\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "mobilenet = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights)\n",
    "mobilenet.classifier[3] = nn.Linear(in_features=1024, out_features=len(classes), bias=True)\n",
    "\n",
    "optimizer = optim.SGD(mobilenet.parameters(),momentum=0.9, lr=parse.lr, weight_decay=5e-4)\n",
    "\n",
    "transfer_learning(mobilenet,\n",
    "                    'mobilenet_v3_small',\n",
    "                    classes,\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    parse,\n",
    "                    data\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Predict***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:42:34.957625Z",
     "iopub.status.busy": "2025-04-12T02:42:34.957393Z",
     "iopub.status.idle": "2025-04-12T02:42:34.963596Z",
     "shell.execute_reply": "2025-04-12T02:42:34.963034Z",
     "shell.execute_reply.started": "2025-04-12T02:42:34.957604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom dataset for flat directory structure\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")) + \n",
    "                                  glob.glob(os.path.join(image_dir, \"*.jpeg\")) + \n",
    "                                  glob.glob(os.path.join(image_dir, \"*.png\")))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Return image and path for identification\n",
    "        return image, os.path.basename(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:42:34.965057Z",
     "iopub.status.busy": "2025-04-12T02:42:34.964430Z",
     "iopub.status.idle": "2025-04-12T02:42:34.983738Z",
     "shell.execute_reply": "2025-04-12T02:42:34.983205Z",
     "shell.execute_reply.started": "2025-04-12T02:42:34.965034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def predict_test(model_path, test_dir=None, batch_size=20, device=None):\n",
    "#     \"\"\"\n",
    "#     Predict and evaluate a trained model on test data using classification_report\n",
    "    \n",
    "#     Args:\n",
    "#         model_path (str): Path to the saved model checkpoint\n",
    "#         test_dir (str): Directory containing test images (flat structure, no class folders)\n",
    "#         batch_size (int): Batch size for inference\n",
    "#         device (torch.device): Device to run inference on (None for auto-detection)\n",
    "        \n",
    "#     Returns:\n",
    "#         dict: Classification report metrics (if ground truth is available)\n",
    "#     \"\"\"\n",
    "#     # Set default directories if not provided\n",
    "#     if test_dir is None:\n",
    "#         test_dir = '/kaggle/input/aio-hutech/test'\n",
    "    \n",
    "#     # Auto-detect device if not specified\n",
    "#     if device is None:\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     class_names = classes\n",
    "\n",
    "#     # Load test data\n",
    "#     test_transforms = Compose([\n",
    "#             RandomResizedCrop(224),\n",
    "#             RandomHorizontalFlip(),\n",
    "#             ToTensor(),\n",
    "#             Normalize([0.574, 0.574, 0.574], [0.169, 0.169, 0.169])\n",
    "#         ])\n",
    "\n",
    "#     # Create test dataset with our custom class\n",
    "#     test_dataset = TestImageDataset(test_dir, transform=test_transforms)\n",
    "    \n",
    "#     if len(test_dataset) == 0:\n",
    "#         raise FileNotFoundError(f\"No image files found in {test_dir}\")\n",
    "#     print(f\"Found {len(test_dataset)} test images\")\n",
    "    \n",
    "#     test_loader = DataLoader(\n",
    "#         dataset=dataset,\n",
    "#         batch_size=20,\n",
    "#         shuffle=True,\n",
    "#         num_workers=4\n",
    "#     )\n",
    "\n",
    "#     # Load the model\n",
    "#     model = mobilenet\n",
    "\n",
    "#     # Run inference\n",
    "#     all_preds = []\n",
    "#     all_filenames = []\n",
    "    \n",
    "#     print(\"Running inference on test data...\")\n",
    "#     with torch.no_grad():\n",
    "#         for images, filenames in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "#             images = images.to(device)\n",
    "            \n",
    "#             outputs = model(images)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_filenames.extend(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dir = temp_val\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "class_names = classes\n",
    "model = mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:42:34.985742Z",
     "iopub.status.busy": "2025-04-12T02:42:34.985566Z",
     "iopub.status.idle": "2025-04-12T02:42:35.618721Z",
     "shell.execute_reply": "2025-04-12T02:42:35.617616Z",
     "shell.execute_reply.started": "2025-04-12T02:42:34.985729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 200 test images\n",
      "Running inference on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 17.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_transforms = Compose([\n",
    "        RandomResizedCrop(224),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize([0.574, 0.574, 0.574], [0.169, 0.169, 0.169])\n",
    "    ])\n",
    "\n",
    "# Create test dataset with our custom class\n",
    "test_dataset = TestImageDataset(test_dir, transform=test_transforms)\n",
    "\n",
    "if len(test_dataset) == 0:\n",
    "    raise FileNotFoundError(f\"No image files found in {test_dir}\")\n",
    "print(f\"Found {len(test_dataset)} test images\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=20,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run inference\n",
    "all_preds = []\n",
    "all_filenames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Running inference on test data...\")\n",
    "with torch.no_grad():\n",
    "    for images, filenames in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_filenames.extend(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'id': [os.path.splitext(filename)[0] for filename in all_filenames],\n",
    "    'type': all_preds\n",
    "    # 'predicted_class': [class_names[idx] for idx in all_preds]\n",
    "}).sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:51:18.991488Z",
     "iopub.status.busy": "2025-04-12T02:51:18.990788Z",
     "iopub.status.idle": "2025-04-12T02:51:19.011529Z",
     "shell.execute_reply": "2025-04-12T02:51:19.010952Z",
     "shell.execute_reply.started": "2025-04-12T02:51:18.991469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:51:20.573765Z",
     "iopub.status.busy": "2025-04-12T02:51:20.573229Z",
     "iopub.status.idle": "2025-04-12T02:51:20.585343Z",
     "shell.execute_reply": "2025-04-12T02:51:20.584694Z",
     "shell.execute_reply.started": "2025-04-12T02:51:20.573740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.24      0.23        50\n",
      "           1       0.30      0.34      0.32        50\n",
      "           2       0.24      0.26      0.25        50\n",
      "           3       0.28      0.18      0.22        50\n",
      "\n",
      "    accuracy                           0.26       200\n",
      "   macro avg       0.26      0.26      0.25       200\n",
      "weighted avg       0.26      0.26      0.25       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df[\"type\"], results_df[\"type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T02:51:24.283359Z",
     "iopub.status.busy": "2025-04-12T02:51:24.283064Z",
     "iopub.status.idle": "2025-04-12T02:51:24.289018Z",
     "shell.execute_reply": "2025-04-12T02:51:24.288329Z",
     "shell.execute_reply.started": "2025-04-12T02:51:24.283339Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to CSV\n",
    "csv_path = 'submission.csv'\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved predictions to {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7119292,
     "sourceId": 11372195,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
